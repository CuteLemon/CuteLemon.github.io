构建机器学习模型，从安然邮件以及财务数据集中找出嫌犯。

### 数据集背景
- 概述  
经过处理的训练集包含21个财务和电子邮件特征。共有146人，被标记为嫌疑人的有18人。部分特征的数据缺失严重，缺失超过50%的有deferred_payments,deferred_income,director_fees,restricked_stock_deferred。
- 异常值  
数据集中存在’TOTAL'，‘THE TRAVEL AGENCY IN THE PARK’之类的异常值。进一步的追查数据源，发现异常值的来源是输入数据时的错误，予以删除。'LOCKHART EUGENE E'除了poi的标记为False，其他内容都是NA，无法得知该数据产生的原因，予以保留。


### 特征选择
-    选择的特征： 回顾整个安然事件，股票是嫌疑犯牟利的工具之一。因此财务特征中将bonus/total_stock_value/exercise_stock_options/restricked_stock_deferred作为了备选特征。 有理由相信：与嫌犯拥有更多邮件往来的人有更大的欺诈嫌疑。邮件特征中备选shared_receipt_with_poi,from_poi_to_this_person，from_this_person_to_poi。
-    设计的新特征：poi_related_msg_rate,与poi的通信邮件占所有邮件的百分比。该值越高说明与已知嫌疑犯的联系越紧密。该特征的加入对决策树的f1分数提升在1%左右。
- 特征缩放：使用MinMaxScale部署了特征缩放。对于KNN算法，该过程是必须的，必须确保每个特征的权重不因特征的数值大小而不同。
- 特征选择：对于决策树算法，将所有备选特征都放入决策树算法中。查看特征的基尼系数，即可知道该特征在分类算法中的相对重要程度。然后去掉一些系数极小的特征得到最终的特征集。对于KNN算法，手工选择两组特征集，评判两组特征集在KNN模型中的F1分数。但由于两组特征集的f1分数都是零（召回率为零），无法进行比较，遂选择精确度较高的作为最终的特征集。
-    特征重要性：

|特征| 	Gini importance|
|--|--|--|
|shared_receipt_with_poi| 	0.364
|exercised_stock_options| 	0.267
|total_payments| 	0.264
|from_this_person_to_poi| 	0.105

### 算法选择
- KNN： KNN在建模时的F1分数为零。但值得指出的是，虽然KNN在验证集上F1为零，但是在最后的全测试集上的F1分数也还尚可。
- 决策树：决策树在测试集上的F1分数对特征集并不太敏感（是否去掉基尼系数接近零的特征，F1分数都维持0.33左右），为了减少过拟合的可能，仍然将基尼系数接近零的特征去掉。
- 最终选择： 基于验证集上的表现选择了决策树。

以下是两种模型在最终测试集上的表现。

||	精确度| 	召回度| 	F1-score|
|--|--|--|--|
|Decision Tree| 	0.414| 	0.421 |	0.418|
|KNN 	|0.369| 	0.343| 	0.355|

对指标的通俗解释

-    精确度：该值越高，则错把嫌疑犯标记为无辜者的比率越小。
-    召回度：该值越高，则错把无辜者标记为嫌疑犯的比率越小。

#### 最佳参数
需要设置相关参数确保算法的bias-variance平衡。不精细的调整的参数会让模型处于过拟合或欠拟合的状态——这都会导致模型在测试集的表现不佳。本项目中通过grid-search自动选择最佳参数。对于KNN，给出n_neighbors的取值。对于决策树，给出min_samples_split的取值。具体做法是手工给出参数值的遍历范围，GridSearchCV会遍历每个参数组合，该方法在参数数量不多，且算法执行时间较短时非常方便。

验证即通过实验对模型的泛化误差进行评估。只有验证的结果才能正确的评价模型的优劣。典型错误是使用训练集作为验证，这非常容易导致过拟合的发生，使得模型的泛化能力不足。本项目使用k折交叉验证作为验证的方法。


### 代码框架
对于这个特定的问题，一开始并不能确定哪种算法会比较适合。训练集容量太小也是个问题。此种情况下，多尝试几个模型总是有益的。为了避免一些重复编码，将待验证的特征集合组成列表，即

```python
f1 = [x1,x2,x3]
f2 = [x3,x7,x9]
feature_list.append(f1)
feature_list.append(f2)

```

待选择的模型也组合成一个列表

```python
def model_generate():
	model_list = []

	para_DT = {'min_samples_split':[2,3,4,5,6,7,8]}
    DT = DecisionTreeClassifier()
    clf_DT = GridSearchCV(DT,para_DT)
    model_list.append(clf_DT)

    para_KNN = {'n_neighbors':[1,2,3,4,5]}
    KNN = KNeighborsClassifier()
    clf_KNN = GridSearchCV(KNN,para_KNN)
    model_list.append(clf_KNN)

    return model_list
```

选择最优模型+最佳参数

```python
def selectBestModel(model_list,features_train,labels_train,features_test,labels_test):
    # estimate each model in the model list
    f1_list = []
    for model in model_list:
        model.fit(features_train,labels_train)
        model = model.best_estimator_
        pred = model.predict(features_test)
        f1 = f1_score(labels_test,pred)
        f1_list.append(f1)

    # pick out the highest f1-score model
    i = max(f1_list)
    index = f1_list.index(i)
    print 'best model:'
    print model_list[index].best_estimator_
    print 'best f1_score: '+ str(i)

    return model_list[index].best_estimator_,i

```
选择最优特征+最优模型+最佳参数

```python
def forDump():
	# feature ,score,model
    f_list = []
    s_list = []
    m_list = []
    for feature in feature_set:
        print '---------------------------------------------'
        print 'features_list:'
        for m in feature:
            print m
        print '##############'
        data,f_train,f_test,l_train,l_test = selectFeatures(feature)
        model_list = model_generate()
        model,f1 = selectBestModel(model_list,f_train,l_train,f_test,l_test)

        f_list.append(feature)
        s_list.append(f1)
        m_list.append(model)

    i = max(s_list)
    index = s_list.index(i)
    best_model = m_list[index]
    best_features = f_list[index]
    return best_model,data,feature
```


## 参考资料

[标签传播算法](https://en.wikipedia.org/wiki/Label_Propagation_Algorithm)
